<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Maxim Egorov">
  
  <title>Defining a POMDP - POMDPs.jl</title>
  

  <link rel="shortcut icon" href="../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../assets/Documenter.css" rel="stylesheet">

  
  <script>
    // Current page data
    var mkdocs_page_name = "Defining a POMDP";
    var mkdocs_page_input_path = "def_pomdp.md";
    var mkdocs_page_url = "/def_pomdp/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script>
  <script src="../js/theme.js"></script> 
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
  <script src="../assets/mathjaxhelper.js"></script>

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> POMDPs.jl</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">About</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../install/">Installation</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../get_started/">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Defining a POMDP</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#defining-a-pomdp">Defining a POMDP</a></li>
                
                    <li><a class="toctree-l4" href="#functional-form-pomdp">Functional Form POMDP</a></li>
                
                    <li><a class="toctree-l4" href="#tabular-form-pomdp">Tabular Form POMDP</a></li>
                
                    <li><a class="toctree-l4" href="#continous-pomdp">Continous POMDP</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../def_solver/">Defining a Solver</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../concepts/">Concepts and Architecture</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../api/">API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../faq/">Frequently Asked Questions</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">POMDPs.jl</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Defining a POMDP</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/JuliaPOMDP/POMDPs.jl" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><a id='Defining-a-POMDP-1'></a></p>
<h1 id="defining-a-pomdp">Defining a POMDP</h1>
<p>The expressive nature of POMDPs.jl gives problem writers the flexiblity to write their problem in many forms. In this section we will take a look at two ways to write a discrete problem, and a way of writing a continuous problem. </p>
<p><a id='Functional-Form-POMDP-1'></a></p>
<h2 id="functional-form-pomdp">Functional Form POMDP</h2>
<p>The first, and most straighforward way to define a POMDP problem is to implement the model functions that you may need. For example, all POMDPs will need <code>transition</code>, <code>reward</code>, and <code>observation</code> functions. In this example we'll start with the simple Tiger POMDP problem. We want to use the SARSOP solver to compute a policy. To use a solver from JuliaPOMDP, a problem writer must define a set of functions required by the solver. To see what functions are required by SARSOP, check out its documentation <a href="#href">here</a>. </p>
<p>Let's first define the Tiger POMDP type.</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">POMDPs</span> <span class="c"># load the interface</span>
<span class="k">type</span><span class="nc"> TigerPOMDP</span> <span class="o">&lt;:</span> <span class="n">POMDP</span><span class="p">{</span><span class="kt">Bool</span><span class="p">,</span> <span class="kt">Int64</span><span class="p">,</span> <span class="kt">Bool</span><span class="p">}</span> <span class="c"># parametarized inheritance POMDP{state, action, observation}</span>
    <span class="n">r_listen</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># reward for listening (negative)</span>
    <span class="n">r_findtiger</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># reward for finding the tiger (negative)</span>
    <span class="n">r_escapetiger</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># reward for escaping</span>
    <span class="n">p_listen_correctly</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># probbility that we hear the tiger correctly</span>
    <span class="n">discount_factor</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># discount factor</span>
<span class="k">end</span>
<span class="n">TigerPOMDP</span><span class="p">()</span> <span class="o">=</span> <span class="n">TigerPOMDP</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span> <span class="c"># default contructor</span>
</pre></div>


<p>Notice that the <code>TigerPOMDP</code> is inheriting from the abstract <code>POMDP</code> type that comes from POMDPs.jl. The abstract <code>POMDP</code> is parametarized by a <code>Bool</code>, <code>Int64</code>, <code>Bool</code> combination with the syntax <code>TigerPOMDP &lt;: POMDP{Bool, Int64, Bool}</code>. The parametarization defines how we choose to represent the state, actions, and observations in our problem. In the <code>TigerPOMDP</code> we use a boolean to represent our states and observations (because there are two of each) and an integer to represent our actions (because there are 3). If you wanted to create a custom concrete type to represent your states, actions, or observations you could do that as well. Let's say we made a type to represent our states called <code>AwesomeTigerState</code>. That type could contain integers, floats, arrays, or other complex data structures (depending on what's convenient). We would then parametrize the Tiger POMDP in the following way: <code>type TigerPOMDP &lt;: POMDP{AwesomeTigerState, Int64, Bool}</code>.</p>
<p>Now, let's consider another important component of POMDPs, probability distributions. In the POMDPs.jl interface, we think in terms of distribution types. We want to be able to sample from these distriubtions and compute their probability masses or densities. In the Tiger POMDP, our distriubtions are over binary variables (boolean state or observation), so we can implement a simple version of a Bernoulli distribution.</p>
<div class="codehilite"><pre><span></span><span class="k">type</span><span class="nc"> TigerDistribution</span> <span class="o">&lt;:</span> <span class="n">AbstractDistribution</span> <span class="c"># inherits from a POMDPs.jl abstract type</span>
    <span class="n">p</span><span class="p">::</span><span class="kt">Float64</span> <span class="c"># probability of 1</span>
    <span class="n">it</span><span class="p">::</span><span class="n">Vector</span><span class="p">{</span><span class="kt">Bool</span><span class="p">}</span> <span class="c"># pre-allocate the domain of the distriubtion</span>
<span class="k">end</span>
<span class="n">TigerDistribution</span><span class="p">()</span> <span class="o">=</span> <span class="n">TigerDistribution</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="n">true</span><span class="p">,</span> <span class="n">false</span><span class="p">])</span> <span class="c"># default constructo</span>

<span class="n">iterator</span><span class="p">(</span><span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="p">)</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">it</span> <span class="c"># convenience function used by discrete solvers (iterator over the discrete distriubtion)</span>
</pre></div>


<p>Let's implement the pdf and rand function that returns the probability mass and samples from the distribution.</p>
<div class="codehilite"><pre><span></span><span class="c"># returns the probability mass </span>
<span class="k">function</span><span class="nf"> pdf</span><span class="p">(</span><span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="p">,</span> <span class="n">so</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span>
    <span class="n">so</span> <span class="o">?</span> <span class="p">(</span><span class="k">return</span> <span class="n">d</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="k">return</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">d</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
<span class="k">end</span>

<span class="c"># samples the dsitribution</span>
<span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">::</span><span class="n">AbstractRNG</span><span class="p">,</span> <span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">d</span><span class="o">.</span><span class="n">p</span>
</pre></div>


<p>We also want some convenience functions for initializing the distriubtions.</p>
<div class="codehilite"><pre><span></span><span class="n">create_transition_distribution</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerDistribution</span><span class="p">()</span>
<span class="n">create_observation_distribution</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerDistribution</span><span class="p">()</span>
</pre></div>


<p>Let's define our transition, observation, and reward functions.</p>
<div class="codehilite"><pre><span></span><span class="k">function</span><span class="nf"> transition</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">,</span> <span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="o">=</span><span class="n">create_transition_distribution</span><span class="p">(</span><span class="n">pomdp</span><span class="p">))</span>
    <span class="c"># Resets the problem after opening door; does nothing after listening        </span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">1</span> <span class="o">||</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="k">elseif</span> <span class="n">s</span>
        <span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span>
        <span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">end</span>
    <span class="n">d</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> observation</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">,</span> <span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="o">=</span><span class="n">create_observation_distribution</span><span class="p">(</span><span class="n">pomdp</span><span class="p">))</span>
    <span class="c"># correct observation wiht prob pc        </span>
    <span class="n">pc</span> <span class="o">=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">p_listen_correctly</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">s</span> <span class="o">?</span> <span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pc</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">pc</span><span class="p">)</span>
    <span class="k">else</span>
        <span class="n">d</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="k">end</span>
    <span class="n">d</span>
<span class="k">end</span>
<span class="c"># convenience function</span>
<span class="k">function</span><span class="nf"> observation</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">,</span> <span class="n">sp</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">d</span><span class="p">::</span><span class="n">TigerDistribution</span><span class="o">=</span><span class="n">create_observation_distribution</span><span class="p">(</span><span class="n">pomdp</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">observation</span><span class="p">(</span><span class="n">pomdp</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> reward</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">)</span>
    <span class="c"># rewarded for escaping, penalized for listening and getting caught</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">a</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">?</span> <span class="p">(</span><span class="n">r</span><span class="o">+=</span><span class="n">pomdp</span><span class="o">.</span><span class="n">r_listen</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">nothing</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">s</span> <span class="o">?</span> <span class="p">(</span><span class="n">r</span> <span class="o">+=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">r_findtiger</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">r</span> <span class="o">+=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">r_escapetiger</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="n">s</span> <span class="o">?</span> <span class="p">(</span><span class="n">r</span> <span class="o">+=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">r_escapetiger</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">r</span> <span class="o">+=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">r_findtiger</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">r</span>
<span class="k">end</span>
<span class="c"># convenience function</span>
<span class="n">reward</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">,</span> <span class="n">sp</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span> <span class="o">=</span> <span class="n">reward</span><span class="p">(</span><span class="n">pomdp</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>


<p>The last important component of a POMDP are the spaces. There is a special <code>AbstractSpace</code> type in POMDPs.jl which all spaces inherit from. We define the state, action, and observation spaces below as well as functions for intializing them and sampling from them.</p>
<div class="codehilite"><pre><span></span><span class="c"># STATE SPACE</span>
<span class="k">type</span><span class="nc"> TigerStateSpace</span> <span class="o">&lt;:</span> <span class="n">AbstractSpace</span>
    <span class="n">states</span><span class="p">::</span><span class="n">Vector</span><span class="p">{</span><span class="kt">Bool</span><span class="p">}</span> <span class="c"># states are boolean</span>
<span class="k">end</span>
<span class="c"># initialize the state space</span>
<span class="n">states</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerStateSpace</span><span class="p">([</span><span class="n">true</span><span class="p">,</span> <span class="n">false</span><span class="p">])</span>
<span class="c"># for iterating over discrete spaces</span>
<span class="n">iterator</span><span class="p">(</span><span class="n">space</span><span class="p">::</span><span class="n">TigerStateSpace</span><span class="p">)</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">states</span>
<span class="n">dimensions</span><span class="p">(::</span><span class="n">TigerStateSpace</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c"># sample from the state sapce</span>
<span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">::</span><span class="n">AbstractRNG</span><span class="p">,</span> <span class="n">space</span><span class="p">::</span><span class="n">TigerStateSpace</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="o">?</span> <span class="p">(</span><span class="k">return</span> <span class="n">true</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="k">return</span> <span class="n">false</span><span class="p">)</span>

<span class="c"># ACTION SPACE</span>
<span class="k">type</span><span class="nc"> TigerActionSpace</span> <span class="o">&lt;:</span> <span class="n">AbstractSpace</span>
    <span class="n">actions</span><span class="p">::</span><span class="n">Vector</span><span class="p">{</span><span class="kt">Int64</span><span class="p">}</span> <span class="c"># three possible actions</span>
<span class="k">end</span>
<span class="c"># initialize the action space</span>
<span class="n">actions</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerActionSpace</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="c"># iterate of the action space</span>
<span class="n">iterator</span><span class="p">(</span><span class="n">space</span><span class="p">::</span><span class="n">TigerActionSpace</span><span class="p">)</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">actions</span>
<span class="n">dimensions</span><span class="p">(::</span><span class="n">TigerActionSpace</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c"># sample from the aciton space</span>
<span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">::</span><span class="n">AbstractRNG</span><span class="p">,</span> <span class="n">space</span><span class="p">::</span><span class="n">TigerActionSpace</span><span class="p">,</span> <span class="n">a</span><span class="p">::</span><span class="kt">Int64</span><span class="p">)</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">)</span>

<span class="c"># OBSERVATION SPACE</span>
<span class="k">type</span><span class="nc"> TigerObservationSpace</span> <span class="o">&lt;:</span> <span class="n">AbstractSpace</span>
    <span class="n">obs</span><span class="p">::</span><span class="n">Vector</span><span class="p">{</span><span class="kt">Bool</span><span class="p">}</span>
<span class="k">end</span>
<span class="c"># initialize</span>
<span class="n">observations</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerObservationSpace</span><span class="p">([</span><span class="n">true</span><span class="p">,</span> <span class="n">false</span><span class="p">])</span>
<span class="c"># iterate over obs space</span>
<span class="n">iterator</span><span class="p">(</span><span class="n">space</span><span class="p">::</span><span class="n">TigerObservationSpace</span><span class="p">)</span> <span class="o">=</span> <span class="n">space</span><span class="o">.</span><span class="n">obs</span>
<span class="n">dimensions</span><span class="p">(::</span><span class="n">TigerObservationSpace</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c"># sample from the obs sapce</span>
<span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">::</span><span class="n">AbstractRNG</span><span class="p">,</span> <span class="n">space</span><span class="p">::</span><span class="n">TigerObservationSpace</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="o">?</span> <span class="p">(</span><span class="k">return</span> <span class="n">true</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="k">return</span> <span class="n">false</span><span class="p">)</span>
</pre></div>


<p>The last important component of a POMDP is the initial distribution over the state space. In POMDPs.jl we make a strong distinction between this distribution and a belief. In most literature these two concepts are considered the same. However, in most general terms, a belief is something that is mapped to an action using a POMDP policy. If the policy is represented as something other than alpha-vectors (a policy graph, tree, or a reccurent neural netowrk to give a few examples), it may not make sense to think of a belief as a probability distribution over the state space. Thus, in POMDPs.jl we abstract the concept of a belief beyond a probability distribution (of course it can be a probability distriubtion if it makes sense). </p>
<p>In order to reconcile this difference, each policy has a function called <code>initialize_belief</code> which takes in an initial state distirubtion (this is a probability distribution over the state space) and a policy, and converts the distribution into what we call a belief in POMDPs.jl - a representation of a POMDP that is mapped to an action using the policy. </p>
<p>Let's define the initial state distribution function for our POMDP.</p>
<div class="codehilite"><pre><span></span><span class="n">initial_state_distribution</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">TigerDistribution</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="n">true</span><span class="p">,</span> <span class="n">false</span><span class="p">])</span>
</pre></div>


<p>Now that've defined all the main components, we need to wrap up our model by creating some convenience functions below.</p>
<div class="codehilite"><pre><span></span><span class="c"># initialization functions</span>
<span class="n">create_state</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="kt">Bool</span><span class="p">)</span>
<span class="n">create_observation</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="kt">Bool</span><span class="p">)</span>
<span class="n">create_action</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="kt">Int64</span><span class="p">)</span>

<span class="c"># for discrete problems</span>
<span class="n">n_states</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_actions</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_observations</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c"># for indexing discrete states</span>
<span class="n">state_index</span><span class="p">(::</span><span class="n">TigerPOMDP</span><span class="p">,</span> <span class="n">s</span><span class="p">::</span><span class="kt">Bool</span><span class="p">)</span> <span class="o">=</span> <span class="kt">Int64</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">discount</span><span class="p">(</span><span class="n">pomdp</span><span class="p">::</span><span class="n">TigerPOMDP</span><span class="p">)</span> <span class="o">=</span> <span class="n">pomdp</span><span class="o">.</span><span class="n">discount_factor</span>
</pre></div>


<p>Now that we've defined all these functions, we can use one of the JuliaPOMDP solvers to compute and evaluate a policy. </p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">QMDP</span><span class="p">,</span> <span class="n">POMDPToolbox</span>

<span class="n">pomdp</span> <span class="o">=</span> <span class="n">TigerPOMDP</span><span class="p">()</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">QMDPSolver</span><span class="p">()</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">pomdp</span><span class="p">)</span>

<span class="n">init_dist</span> <span class="o">=</span> <span class="n">initial_state_distribution</span><span class="p">(</span><span class="n">pomdp</span><span class="p">)</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">HistoryRecorder</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="c"># from POMDPToolbox</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">simulate</span><span class="p">(</span><span class="n">hist</span><span class="p">,</span> <span class="n">pomdp</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">belief_updater</span><span class="p">,</span> <span class="n">init_dist</span><span class="p">)</span> <span class="c"># run 100 step simulation</span>
</pre></div>


<p>Please note that you do not need to define all the functions for most solvers. If you want to use an individual solver, you usually need only a subset of what's above. </p>
<p><a id='Tabular-Form-POMDP-1'></a></p>
<h2 id="tabular-form-pomdp">Tabular Form POMDP</h2>
<p>Another way to define discrete POMDP problems is by writing them in tabular form. Specifically, if you can write the transition and observation probabilities as well as the rewards in matrix form, you can use the <code>DiscreteMDP</code> or <code>DiscretePOMDP</code> types form <code>POMDPModels</code> which automatically implements all the functions you'll need for you. Let's do this with the Tiger POMDP.</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">POMDPModels</span>

<span class="c"># write out the matrix forms</span>

<span class="c"># REWARDS</span>
<span class="n">R</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span> <span class="o">-</span><span class="mi">100</span> <span class="mi">10</span><span class="p">;</span> <span class="o">-</span><span class="mi">1</span> <span class="mi">10</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="c"># |S|x|A| state-action pair rewards</span>

<span class="c"># TRANSITIONS</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c"># |S|x|A|x|S|, T[s&#39;, a, s] = p(s&#39;|a,s)</span>
<span class="n">T</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">;</span> <span class="mi">0</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">T</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">;</span> <span class="mi">1</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">]</span>

<span class="c"># OBSERVATIONS</span>
<span class="n">O</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c"># |O|x|A|x|S|, O[o, a, s] = p(o|a,s)</span>
<span class="n">O</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.85</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">;</span> <span class="mf">0.15</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">O</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.15</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">;</span> <span class="mf">0.85</span> <span class="mf">0.5</span> <span class="mf">0.5</span><span class="p">]</span>

<span class="n">discount</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">pomdp</span> <span class="o">=</span> <span class="n">DiscretePOMDP</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">discount</span><span class="p">)</span>

<span class="c"># solve the POMDP the same way</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">SARSOPSolver</span><span class="p">()</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">pomdp</span><span class="p">)</span>
</pre></div>


<p>It is usually fairly simple to define smaller problems in the tabular form. However, for larger problems it can be tedious and the functional form may be preffered. You can usually use any supported POMDP solver to sovle these types of problems (the performance of the policy may vary however - SARSOP will usually outperform QMDP). </p>
<p><a id='Continous-POMDP-1'></a></p>
<h2 id="continous-pomdp">Continous POMDP</h2>
<p>Within the POMDPs.jl interface, we can also define problems with continuous spaces. There are a few solvers that can handle these types of problems, namely, MCVI and POMCP (with some tunning). Light-Dark problem here. What should we say about bounds? This is a good place to discuss GenerativeModels. Would also be good if we could include RL stuff somewhere (depending on Chris). </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../def_solver/" class="btn btn-neutral float-right" title="Defining a Solver">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../get_started/" class="btn btn-neutral" title="Getting Started"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/JuliaPOMDP/POMDPs.jl" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../get_started/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../def_solver/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
